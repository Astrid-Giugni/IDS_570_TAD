<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Week 07: Word2Vec and LDA introduction – Text as Data: Language Models, AI, and NLP Techniques for Historical and Literary Texts</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-b57d1312aa7c10f38068bb8d7c282b76.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Text as Data</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week-01-introduction.html">Weeks</a></li><li class="breadcrumb-item"><a href="./week-07-word2vec.html">Week 07: Word2Vec and LDA introduction</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Course</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">IDS 570: “Text as Data: Language Models, AI, and NLP Techniques for Historical and Literary Texts”</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Weeks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-01-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 01: Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-02-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 02: Basics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-03-dictionaries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 03: Dictionaries</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-04-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 04: Text Representation (1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-05-representation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 05: Text Representation (2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-06-cooccurrence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 06: Co-occurrence &amp; PMI</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-07-word2vec.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Week 07: Word2Vec and LDA introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week-08-09-word2vec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Week 07: Weeks 08 &amp; 9: Weak Supervision &amp; Supervised Text Classification in Python</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week-01-introduction.html">Weeks</a></li><li class="breadcrumb-item"><a href="./week-07-word2vec.html">Week 07: Word2Vec and LDA introduction</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Week 07: Word2Vec and LDA introduction</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="step-0-transition-to-python" class="level2">
<h2 class="anchored" data-anchor-id="step-0-transition-to-python">Step 0: Transition to Python</h2>
<p>Before working with text in today’s tutorial, we are going to have an introduction to getting started in Python. This is for those of you who haven’t worked in Python before. <strong>Note</strong>: this doesn’t mean that you want to forget everything that you learned in R up to now! The analyses that we conducted in R allowed us to develop a granular understanding of how to represent and measure textual features. The tasks we will do in Python will be less “transparent”, but you don’t want to give up the intuition you developed so far.</p>
<p>If you have never worked with Python, you can find a beginner friendly, step by step guide on how to download Python and set up VS Code (the environment you will use for Python–think of it as the Python version of R studio): <a href="https://code.visualstudio.com/docs/python/python-tutorial"><strong>here</strong></a>.</p>
<p>If you have worked with Python before, you can use whichever environment you want.</p>
<p><strong>Quick note</strong>: you want Python 3.11.x. The bottleneck is scikit-learn, which doesn’t play well with the most recent version of Python.</p>
<p><strong>A second note about learning Python:</strong> If you are new to Python, the first thing that you will see as you look at tutorials is that Python is an <a href="https://realpython.com/python3-object-oriented-programming/"><strong>object-oriented language</strong></a>. I have added a link that takes you to <a href="https://realpython.com/">realpython.com</a>, which is a great resource for learning Python. But don’t worry too much about understanding all the finer points of this from the get-go! The TA’s and I will help you use the code that I give you as an example and then you can start learning more about objects and classes and all that jazz.</p>
<ul>
<li>As we go along this tutorial: I am re-introducing the training wheels. I am including links to some of the major Python concepts as they come up in the code!</li>
</ul>
<section id="getting-started-reading-tokenizing-and-stop-words" class="level3">
<h3 class="anchored" data-anchor-id="getting-started-reading-tokenizing-and-stop-words">Getting started: reading, tokenizing, and stop words</h3>
<p>The first few steps that we are going to take are very similar to what we did in R: the logic is the same, but the syntax is different. The first thing that we need to do is to read the text and then check that things look correct!</p>
<p>In R, what we do at the beginning is:</p>
<ul>
<li><p>load a text file into memory,</p></li>
<li><p>check how long it is,</p></li>
<li><p>preview the beginning,</p></li>
<li><p>and try to spot obvious encoding or OCR problems early (that is, does the text look weird?).</p></li>
</ul>
<p>We are now going to do the same step in Python. The main difference is that we are going to use a <a href="https://realpython.com/python-pathlib/"><strong>path-handling tool</strong></a> in Python, <code>Path</code>. We are then going to actually read the file with this line: <code>text = path.read_text(encoding="utf-8", errors="replace")</code>. Here, I am asking Python to decode the text using <code>utf-8</code> and to replace any unreadable characters instead of crashing. The replacement is the Unicode replacement character: �.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path(<span class="st">"texts/wealth.txt"</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> path.read_text(encoding<span class="op">=</span><span class="st">"utf-8"</span>, errors<span class="op">=</span><span class="st">"replace"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># The lines above read the wealth.txt into a long string</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Characters:"</span>, <span class="bu">len</span>(text)) <span class="co">#character count </span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Characters: 2411473</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Lines:"</span>, text.count(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>) <span class="op">+</span> <span class="dv">1</span>) <span class="co">#line count</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Lines: 34544</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># taking a look that the text looks ok. Similar to head() and slice() in R</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- START ---</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- START ---</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text[:<span class="dv">800</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>An Inquiry into the Nature and Causes of the Wealth of Nations

by Adam Smith




Contents


 INTRODUCTION AND PLAN OF THE WORK.

 BOOK I. OF THE CAUSES OF IMPROVEMENT IN THE PRODUCTIVE
POWERS OF labor, AND OF THE ORDER ACCORDING TO WHICH ITS PRODUCE IS NATURALLY
DISTRIBUTED AMONG THE DIFFERENT RANKS OF THE PEOPLE.
 CHAPTER I. OF THE DIVISION OF labor.
 CHAPTER II. OF THE PRINCIPLE WHICH GIVES OCCASION TO THE
DIVISION OF labor.
 CHAPTER III. THAT THE DIVISION OF labor IS LIMITED BY
THE EXTENT OF THE MARKET.
 CHAPTER IV. OF THE ORIGIN AND USE OF MONEY.
 CHAPTER V. OF THE REAL AND NOMINAL PRICE OF
COMMODITIES, OR OF THEIR PRICE IN labor, AND THEIR PRICE IN MONEY.
 CHAPTER VI. OF THE COMPONENT PART OF THE PRICE OF COMMODITIES.
 CHAPTER VII. OF THE NATURAL AND MARKET PRICE OF COMMODITIES.
 CHA</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>mid <span class="op">=</span> <span class="bu">len</span>(text)<span class="op">//</span><span class="dv">2</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- MIDDLE SLICE ---</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- MIDDLE SLICE ---</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text[mid:mid<span class="op">+</span><span class="dv">800</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code> Though there are in Europe indeed, a few towns which, in same respects,
      deserve the name of free ports, there is no country which does so.
      Holland, perhaps, approaches the nearest to this character of any, though
      still very remote from it; and Holland, it is acknowledged, not only
      derives its whole wealth, but a great part of its necessary subsistence,
      from foreign trade.

      There is another balance, indeed, which has already been explained, very
      different from the balance of trade, and which, according as it happens to
      be either favorable or unfavorable, necessarily occasions the prosperity
      or decay of every nation. This is the balance of the annual produce and
      consumption. If the exchangeable value of the annual produce, it has
 </code></pre>
</div>
</div>
<p>The <code>print()</code> function is something that will come up over and over again. If you get lost by how I am using it, do click on this <a href="https://realpython.com/python-print/"><strong>explanation</strong></a>.</p>
<p>The next step is to tokenize the text. This is the Python version of <code>unnest_tokens()</code> in tidytext. But in Python, we have to do this using a regex: so, hopefully, you feel comfortable with the regex unit from Week 2. We are also going to lowercase. This tokenizer keeps alphabetic words (and contractions), so it ignores numbers and hyphenated compounds; that’s a simplification for today, not a general rule.</p>
<p>Since we also want to run some checks on our process (as we did in R), we are going to inspect the most frequent tokens using <a href="https://realpython.com/python-counter/"><code>Counter</code></a>, the Python parallel to tidytext’s <code>count(word, sort =TRUE)</code>.</p>
<p><strong>Making things look nicer:</strong> You can skip this explanation, if you are new to Python. This is equivalent to: <code>print(w, c)</code>. I am just trying to make the display more readable for the class!</p>
<p>In the next block below, I am going to use an <code>f-string</code> inside <code>print()</code>. An <code>f-string</code> is a way to format text, so <code>f"{w:&gt;12} {c}"</code> means (working inside out):</p>
<ul>
<li><p>take the value of <code>w</code> and convert it to text, right-align it inside a space 12 character wide;</p></li>
<li><p>then when you print separate the columns (the two spaces between <code>{w:&gt;12}</code> and <code>{c}</code>)</p></li>
</ul>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> re.findall(<span class="vs">r"</span><span class="pp">[A-Za-z]</span><span class="op">+</span>(?:<span class="vs">'</span><span class="pp">[A-Za-z]</span><span class="op">+</span>)<span class="op">?</span><span class="vs">"</span>, text.lower())</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokens:"</span>, <span class="bu">len</span>(tokens))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tokens: 380080</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Unique tokens:"</span>, <span class="bu">len</span>(<span class="bu">set</span>(tokens)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unique tokens: 9475</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> Counter(tokens)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Top 25 tokens:"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Top 25 tokens:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w, c <span class="kw">in</span> counts.most_common(<span class="dv">25</span>):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w<span class="sc">:&gt;12}</span><span class="ss">  </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>         the  32244
          of  24295
          to  11708
         and  10284
          in  9637
           a  6678
          it  5392
       which  4824
          is  4685
          be  3828
        that  3818
          or  3211
          as  3088
          by  2981
         for  2976
       their  2523
        this  2231
         not  2231
         are  2168
        they  2131
        have  2119
        upon  2112
        from  1970
         but  1962
       those  1925</code></pre>
</div>
</div>
<p>The library <a href="https://scikit-learn.org/stable/"><strong>Scikit-learn</strong></a> is going to allow us to import a standard list of stopwords. More importantly, <code>Scikit-learn</code> is a machine learning library for Python and we will use it more than once!</p>
<p>We are going to convert the list of pre-defined stopwords into a <a href="https://realpython.com/python-sets/"><strong>set</strong></a> because it will make filtering tokens more efficient. We can then use the <strong>in-place OR operator</strong> <code>|=</code> to add all the elements of our custom stopwords to the standard stopwords (the link at “sets” will also explain <code>|=</code>).</p>
<p><strong>Aside:</strong> if you go to the tutorial, you might see that there is another <strong>OR operator</strong> <code>|</code> . This operator creates a new set. I am just modifying the preexisting one by adding the custom stopwords.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> ENGLISH_STOP_WORDS</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>stopwords <span class="op">=</span> <span class="bu">set</span>(ENGLISH_STOP_WORDS) <span class="co">#turn it into a set</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This is optional and I am only using this as an example of syntax (hence the choice of silly terms)</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>custom_stopwords <span class="op">=</span> {<span class="st">"barnacle"</span>, <span class="st">"putine"</span>}</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>stopwords <span class="op">|=</span> custom_stopwords</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># let's check how many stopwords we have and what they look like</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Stopwords loaded:"</span>, <span class="bu">len</span>(stopwords))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Stopwords loaded: 320</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sample:"</span>, <span class="bu">sorted</span>(<span class="bu">list</span>(stopwords))[:<span class="dv">25</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample: ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any']</code></pre>
</div>
</div>
<p>Now that we have our stopwords as we want them, we can apply it to our tokens. We are also going to remove really short tokens (fewer than 3 characters). Something that sometimes throws people off: I am stating the length requirement as a strict inequality. Now look at the code below: do you understand why have <code>len(t) &gt;= 3</code> ?</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>clean_tokens <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens <span class="cf">if</span> t <span class="kw">not</span> <span class="kw">in</span> stopwords <span class="kw">and</span> <span class="bu">len</span>(t) <span class="op">&gt;=</span> <span class="dv">3</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokens (raw):"</span>, <span class="bu">len</span>(tokens))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tokens (raw): 380080</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tokens (clean):"</span>, <span class="bu">len</span>(clean_tokens))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tokens (clean): 148917</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Unique tokens (clean):"</span>, <span class="bu">len</span>(<span class="bu">set</span>(clean_tokens)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unique tokens (clean): 9156</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>clean_counts <span class="op">=</span> Counter(clean_tokens)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Top 25 tokens after cleaning:"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Top 25 tokens after cleaning:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w, c <span class="kw">in</span> clean_counts.most_common(<span class="dv">25</span>):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w<span class="sc">:&gt;12}</span><span class="ss">  </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>       great  1583
       price  1264
     country  1240
     greater  1085
       labor  1011
       trade  970
     produce  945
   different  855
    quantity  797
       value  794
      people  779
       money  773
        land  720
     revenue  691
      silver  661
     capital  657
        time  636
       stock  601
       goods  585
      market  582
   countries  577
     expense  561
  particular  513
         tax  513
        gold  508</code></pre>
</div>
</div>
</section>
<section id="segmenting-the-text-and-preparing-for-word2vec-and-lda" class="level3">
<h3 class="anchored" data-anchor-id="segmenting-the-text-and-preparing-for-word2vec-and-lda">Segmenting the text and preparing for Word2Vec and LDA</h3>
<p>So far, the steps should be very familiar (with a different coding language). The next step is driven by the model itself. Since LDA does not operate on individual words or on a continuous token stream, we are going to be constrained by the structure that it needs. Word2Vec <em>can</em> work on the entire <em>Wealth of Nations</em> at once, but for the sake of continuity, we will stick to the same structure for both models.</p>
<p>LDA needs to work with documents or, as in our case, pre-defined segments of a longer text. These are the assumptions behind LDA:</p>
<ul>
<li><p>each document is a mixture of topics,</p></li>
<li><p>each topic is a distribution over words.</p></li>
</ul>
<p>This forces us to decide what counts as a “document” in our corpus. In some cases, this will be obvious to you: if you have a collection of political speeches, then each speech is a document. In other cases, we have to make a decision. <em>The Wealth of Nations</em> is one long text and we can segment it in a number of ways. There are two common options (each with its one trade-offs): one is to use internal subdivisions, such as chapters; the other is to use fixed-sized segments. We are going to go for the second one and create 800-token chunks.</p>
<p><strong>Note:</strong> both options are legitimate choices. I am picking fixed-sized segments <em>because</em> I know that the chapters in <em>The Wealth of Nations</em> are of varied length and that a single topic (such as labor or political economy) is split over several chapters. The approach I take here also ensures that no single segment dominates the model simply because of its length. LDA <em>tends</em> to work better when documents are not extremely long. But this choice comes with a trade-off: I am losing track of Adam Smith’s structure. For different purposes (that is, for an actual project rather than a class tutorial), I might choose to “chunk” by chapter instead.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Segmenting</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>SEGMENT_SIZE <span class="op">=</span> <span class="dv">800</span>  <span class="co"># fixed-size "document." We can always adjust length</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># slice the entire list of tokens from token #0 to the last token, breaking it into chunks of SEGMENT_SIZE.</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>segments <span class="op">=</span> [</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    clean_tokens[i:i<span class="op">+</span>SEGMENT_SIZE] </span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(clean_tokens), SEGMENT_SIZE)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co">#inspect the segmentation</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of segments:"</span>, <span class="bu">len</span>(segments))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of segments: 187</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First segment length:"</span>, <span class="bu">len</span>(segments[<span class="dv">0</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>First segment length: 800</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Last segment length:"</span>, <span class="bu">len</span>(segments[<span class="op">-</span><span class="dv">1</span>]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last segment length: 117</code></pre>
</div>
</div>
<p>Each segment is now a document for LDA: we have 186 segments, which is a good document count for LDA, and segment sizes are consistent (800; last shorter, which is what we expect). Note: I picked 800 somewhat arbitrarily, but it is meant to capture approximately 2-3 paragraphs per segment given what I know of Smith’s writing. Let’s see what word counts in a segment look like:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>segment_counts <span class="op">=</span> [Counter(seg) <span class="cf">for</span> seg <span class="kw">in</span> segments]</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check: top words in segment 0</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top words in segment 0:"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top words in segment 0:</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> w, c <span class="kw">in</span> segment_counts[<span class="dv">0</span>].most_common(<span class="dv">15</span>):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w<span class="sc">:&gt;12}</span><span class="ss">  </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>     chapter  33
       labor  30
   different  19
        book  12
     produce  11
    division  11
    employed  11
     nations  10
     society  10
      number  10
        work  9
       stock  8
  particular  8
      people  7
       great  7</code></pre>
</div>
</div>
<p>This also looks reasonable for the opening of the book (chapter, book, division, labor, work, nations, society) and it means that we can proceed to the next step.</p>
<p>At this point, we now have two complementary representations of the same text:</p>
<ul>
<li><p><strong><code>segments</code></strong>: each segment is an ordered sequence of tokens</p></li>
<li><p><strong><code>segment_counts</code></strong>: each segment is represented by word counts (bag-of-words)</p></li>
</ul>
<p>We are going to need both representations, but for two different models. <u>Word2Vec</u> learns meaning from <em>local context and word order</em>, so it can work directly with <code>segments</code>. On the other hand, <u>LDA</u> ignores word order and models documents as mixtures of topics, so it requires a bag-of-words representation, which we will build explicitly in the next section.</p>
<p>We will begin with Word2Vec, because it extends ideas you have already encountered: a word’s meaning is shaped by the contexts in which it appears. For a good resource on understanding Word2Vec, see <a href="https://www.tensorflow.org/text/tutorials/word2vec"><u><strong>here</strong></u></a>. But, in short, instead of storing explicit co-occurrence counts, Word2Vec learns dense vectors for each word. These vectors are learned by optimizing a predictive task: <em>given a word, predict its surrounding context (or vice versa)</em>. The result is a compressed, smoothed representation of the same information we previously counted directly.</p>
<p>OK, what does this mean in practice for us? Each segment is a sequence of tokens and Word2Vec slides a fixed-size context window across these sequences and learns vector representations that are good at predicting nearby words.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Key step: Word2Vec training</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Word2Vec  </span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>w2v <span class="op">=</span> Word2Vec(</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    sentences<span class="op">=</span>segments,     <span class="co"># each segment is a list of tokens</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    vector_size<span class="op">=</span><span class="dv">100</span>,        <span class="co"># dimensionality</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    window<span class="op">=</span><span class="dv">5</span>,               <span class="co"># context window (parallel to your co-occurrence window)</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    min_count<span class="op">=</span><span class="dv">10</span>,           <span class="co"># ignore very rare words</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    workers<span class="op">=</span><span class="dv">4</span>,              <span class="co"># number of CPU cores for parallel processing</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    sg<span class="op">=</span><span class="dv">1</span>                    <span class="co"># 1=skip-gram, 0=CBOW</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vocabulary size:"</span>, <span class="bu">len</span>(w2v.wv.key_to_index))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Vocabulary size: 2317</code></pre>
</div>
</div>
<p>We have to make some choices when we train Word2Vec:</p>
<ul>
<li><p><code>vector_size=100</code>: each word is represented as a 100-dimensional vector (if we choose higher dimension, we capture more information about each word, but it’s slower and requires more text data). Common values in practice: 100-300. 100 is often the default.</p></li>
<li><p><code>window=5</code> matches what we did in our co-occurrence calculation.</p></li>
<li><p><code>min_count=10</code> keeps the vocab manageable (and its good for a class exercise). Note: the exact choice of 10 (instead of, say, 15 or 20) is based on trail and error. Given that we have 1,395 words in the vocabulary after filtering, I don’t want to be too agressive. For a larger and more varied corpus, I might go for 20.</p></li>
<li><p><strong>Important:</strong> if you have an older machine and it’s freezing; <code>change workers = 4</code> to 2 or even 1.</p></li>
<li><p><code>sg=1</code> (skip-gram) is usually better for capturing rarer, more specific relations.</p></li>
</ul>
<p>Now that the model is trained, we can inspect its learned semantic space by asking for a word’s <strong>nearest neighbors</strong>. The goal is to use <strong>cosine similarity</strong> to find which word vectors are closest to a given/target word in the vector space. In this case, let’s look at “trade,” “labor,” “price,” “capital,” and “market” to see what kind of results we get.</p>
<ul>
<li>quick aside if you haven’t worked in Python before: this is the first time we are defining a function using the <a href="https://realpython.com/defining-your-own-python-function/#getting-to-know-functions-in-python"><strong>def</strong> keyword</a>.</li>
</ul>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nearest neighbors (cosine similarity)</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_neighbors(word, topn<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> w2v.wv:</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"'</span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">' not in vocabulary."</span>)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Nearest neighbors for '</span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">':"</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w, sim <span class="kw">in</span> w2v.wv.most_similar(word, topn<span class="op">=</span>topn):</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w<span class="sc">:&gt;12}</span><span class="ss">  </span><span class="sc">{</span>sim<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> target <span class="kw">in</span> [<span class="st">"trade"</span>, <span class="st">"labor"</span>, <span class="st">"price"</span>, <span class="st">"capital"</span>, <span class="st">"market"</span>]:</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    show_neighbors(target, topn<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Nearest neighbors for 'trade':
    carrying  0.883
       round  0.850
    branches  0.827
     carried  0.823
advantageous  0.819
      branch  0.817
       carry  0.814
     returns  0.812
      trades  0.807
 restraining  0.793

Nearest neighbors for 'labor':
        puts  0.867
      motion  0.851
 distributed  0.849
     laborer  0.845
        adds  0.833
        vary  0.823
       tools  0.820
       sinks  0.813
      powers  0.813
 constitutes  0.813

Nearest neighbors for 'price':
       rises  0.847
       lower  0.833
         low  0.833
        sink  0.825
      barley  0.816
    somewhat  0.811
       bread  0.810
      prices  0.806
     butcher  0.804
       risen  0.804

Nearest neighbors for 'capital':
    capitals  0.891
       stock  0.852
   withdrawn  0.826
    replaces  0.825
       fixed  0.824
       yield  0.821
     employs  0.817
   wholesale  0.811
      unless  0.807
     farming  0.805

Nearest neighbors for 'market':
   effectual  0.778
     thither  0.758
     markets  0.755
    supplied  0.754
     cheaper  0.753
     brought  0.753
    somewhat  0.753
        come  0.752
      dearer  0.750
   supplying  0.747</code></pre>
</div>
</div>
<p>For <strong>trade</strong>: the terms that we are getting indicate that Smith is using structural and institutional language in conjunction with this term. We have verbs like carrying, carried, and shipping (possibly used as a noun…), as well as structural qualifiers such as branches, returns, and direct. Some words are perhaps more surprising and would require more investigation (such as round).</p>
<p>For <strong>labor:</strong> there is a strong sign the model has learned labor as an activity embedded in the language of key economic activities, such as productive, distributed, enables, and, more obviously, but very reassuring, laborer and tools.</p>
<ul>
<li>As an exercise for the students: what do you think of the neighbors for price, capital, and markets? Any surprises?</li>
</ul>
<p>I think that at this point, it will be helpful to compare with the co-occurrence analysis we did last week. Let’s compute simple co-occurrence neighbors using the same as in week 6 (<code>window = 5</code>) and compare.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Co-occurrence neighbors (window = 5)</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter, defaultdict</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>WINDOW <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>cooc <span class="op">=</span> defaultdict(Counter)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> seg <span class="kw">in</span> segments:</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, token <span class="kw">in</span> <span class="bu">enumerate</span>(seg):</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>        start <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, i <span class="op">-</span> WINDOW)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>        end <span class="op">=</span> <span class="bu">min</span>(<span class="bu">len</span>(seg), i <span class="op">+</span> WINDOW <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(start, end):</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">!=</span> j <span class="kw">and</span> seg[j] <span class="op">!=</span> token: <span class="co"># otherwise "trade" will be the closest to "trade" etc.</span></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>                cooc[token][seg[j]] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_cooc_neighbors(word, topn<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Co-occurrence neighbors for '</span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">':"</span>)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w, c <span class="kw">in</span> cooc[word].most_common(topn):</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>w<span class="sc">:&gt;12}</span><span class="ss">  </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now we can look at them and compare with Word2Vec neighbors defined by cosine similarity:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> target <span class="kw">in</span> [<span class="st">"trade"</span>, <span class="st">"labor"</span>, <span class="st">"price"</span>]:</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    show_cooc_neighbors(target, topn<span class="op">=</span><span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Co-occurrence neighbors for 'trade':
     foreign  192
       great  164
     capital  127
     country  119
 consumption  92
    employed  82
     greater  80
     carried  70
    monopoly  68
    branches  67

Co-occurrence neighbors for 'labor':
     produce  227
    quantity  216
       wages  202
       price  193
        land  161
     greater  139
       stock  122
       value  122
  productive  120
     country  119

Co-occurrence neighbors for 'price':
      market  200
       labor  193
       money  158
        corn  142
        real  116
        rise  106
 commodities  104
        high  101
    quantity  94
     produce  90</code></pre>
</div>
</div>
<ul>
<li>What differences do you note in these lists? Both represent “neighbors” of our target words, but obtain through two different methods.</li>
</ul>
</section>
</section>
<section id="lda-topic-modeling" class="level2">
<h2 class="anchored" data-anchor-id="lda-topic-modeling">LDA Topic Modeling:</h2>
<p>Up to this point, we have used Word2Vec to explore how individual words relate to one another based on shared contexts. This approach is well suited to questions like:</p>
<ul>
<li>Which words behave similarly across the text? How is a concept used, qualified, or framed?</li>
</ul>
<p>This is really helpful if you are trying to think about how, for example, different texts portray the same terminology and concepts. But what if we want to focus on the <em>text</em> as a whole instead? This is the question that topic models—and LDA in particular—are designed to answer.</p>
<section id="some-background-on-lda" class="level3">
<h3 class="anchored" data-anchor-id="some-background-on-lda">Some background on LDA:</h3>
<p>In class, we briefly discussed the Dirichlet distribution. I emphasized that you don’t need to know the details in the background in order to actually work with LDA topic modeling. However, you do need to understand some basics about distributions so as to develop some intuition. First, if you need a clear and to the point reminder of binomial distributions, look at <a href="https://www.youtube.com/watch?v=J8jNoF-K8E8"><u><strong>Josh Starmer’s youtube channel</strong></u></a> [he is a faculty member at UNC; not a random channel]. If you want a more robust discussion, see <a href="https://find.library.duke.edu/catalog/DUKE99119538962108501">Peter Dalgaard, <em>Introductory Statistics with R</em></a>&nbsp;(2008), chapter 3 [statistics applications is one of the reasons I started the semester with R]. Once you are comfortable with that, use the discussion in chapter 6 of <em>Text as Data</em> for Dirichlet distribution (or take it on faith for now!).</p>
<p>With that behind us, the next step that we are going to do is the parallel to creating a DFM, but we have to organize our text into the data structure required by LDA. We already have <code>segments</code> and <code>segment_counts</code>, we need a <a href="https://docs.python.org/3/tutorial/datastructures.html"><strong>dictionary</strong></a> (this is a key data structure in Python, follow the link if you are unfamiliar with it) and a document-<strong>term</strong> matrix (D<strong>T</strong>M). LDA works with a “bag-of-words” representation, so we need to get word counts for each segment. This should be very familiar for our work in R.</p>
<p>In the code below, <code>Dictionary</code> builds a vocabulary from our corpus and creates a mapping between each unique word (like “trade”) and a unique integer ID (assigned sequentially, in the order that new words are first encountered when gensim scans the corpus).</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora <span class="im">import</span> Dictionary</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a dictionary from the segments</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>dictionary <span class="op">=</span> Dictionary(segments)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co"># do some cleaning</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>dictionary.filter_extremes(</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    no_below<span class="op">=</span><span class="dv">10</span>,    <span class="co"># must appear in at least 10 segments</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    no_above<span class="op">=</span><span class="fl">0.5</span>   <span class="co"># must appear in no more than 50% of segments</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Vocabulary size after filtering:"</span>, <span class="bu">len</span>(dictionary))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Vocabulary size after filtering: 1711</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert segments to bag-of-words format</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [dictionary.doc2bow(seg) <span class="cf">for</span> seg <span class="kw">in</span> segments]</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Take a look</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First document (bow format):"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>First document (bow format):</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corpus[<span class="dv">0</span>][:<span class="dv">10</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[(0, 1), (1, 3), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]</code></pre>
</div>
</div>
<p>In the filtering step we are mirroring what we did in R when we removed very rare words and stopwords, but with a slightly different logic. Remember, we are trying to create topics and rare words in the corpus won’t really define a what the text is “about,” so we filter out words that appear in fewer than 10 segments by using <code>no_below=10</code> (out of 186 segments). Conversely, really frequent words tend to be too general to distinguish topics, so we filter for words that appear in more than half of the segments using <code>no_above=0.5</code>. <u>Note</u>: both these values are heuristics that tend to work well for a first run of the model. But you might decide that, based on your question, you want to try different filters!</p>
<p>At this point, we have the same kind of data structure we relied on in R for bag-of-words models: <strong>documents represented by word counts</strong>. The next step will simply convert these counts into the specific input format required by the LDA implementation we are using.</p>
<p>We are finally done with preprocessing and we can actually fit the LDA model (yay!). <u>To reiterate</u>: these “topics” are computational constructs; they are estimates of latent word distributions that, taken together, explain the observed word counts reasonably well.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train LDA model</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> LdaModel</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>lda <span class="op">=</span> LdaModel(</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    corpus<span class="op">=</span>corpus,</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    id2word<span class="op">=</span>dictionary,</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    num_topics<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    passes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"LDA model trained."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>LDA model trained.</code></pre>
</div>
</div>
<section id="why-these-hyperparameter-settings" class="level4">
<h4 class="anchored" data-anchor-id="why-these-hyperparameter-settings">Why these hyperparameter settings:</h4>
<ul>
<li><p><code>num_topics=8</code>: small enough to read–it’s a good starting place</p></li>
<li><p><code>passes=10</code>: this is how many times the model goes through the corpus during training. More passes will produce more stable topic estimates, but they take longer to compute. The size of your corpus matters here: with a small corpus, each document will carry a lot of weight and topic estimates are more sensitive to noise, so I will tend to do 10-15 passes. With a larger corpus, you can get away with fewer passes (5-10-ish) because the model encounters each word in more contexts. I don’t have a a clear cut rule because the answer also depends on: “how much time and GPU to you have?”</p>
<ul>
<li><u>A nuanced point</u>: the model also has a default number of <u><strong>iterations</strong></u> that we are not changing. Iterations are different from passes. The iterations control how thoroughly the model updates its estimates during each visit: these are the internal optimization steps that occur during <em>each</em>&nbsp;pass.</li>
</ul></li>
</ul>
<p>When we train an LDA model, we are not only choosing <em>how many</em> topics to use. We are also choosing “how flexible” the model is in assigning topics to documents and words to topics</p>
<ul>
<li><p><code>alpha="auto"</code>: the <code>alpha</code> setting governs the document-topic distribution. That is, does the model assume that documents (segments in our case) tend to focus on one or fewer topics (low <code>alpha</code>) or does it assume that they contain a mix of many topics (higher <code>alpha</code>)? When we set it to <code>"auto"</code>, we allow the model to learn this behavior from the data. I chose <code>"auto"</code> because we created arbitrary segments in the text based on a pre-selected number of tokens. If I had a different corpus, I would have to think more about <code>alpha</code>.</p>
<ul>
<li><p>What does this mean? In <code>gensim</code>‘s LDA implementation, the default setting for the <code>alpha</code> parameter is ’symmetric’. This means that alpha has the same value for all topics. When <code>alpha</code> is symmetric, gensim calculates it using this formula: <span class="math inline">\(\alpha\)</span> = 1.0 / number of topics. When I say that based on the structure of the corpus, I would have to think about it more, I mean this quite literally: I will base my decisions on the exact question that I am asking with topic modelling and the details of the corpus.</p></li>
<li><p>If you really want to dig into this, here are the resources that I would review before making these decisions: “<a href="https://www.pnas.org/doi/10.1073/pnas.0307752101">Finding scientific topics</a>” (2004); “<a href="https://aclanthology.org/D11-1024.pdf">Optimising Semantic Coherence in Topic Models</a>” (2011); and for good measure, I am including the original paper on LDA, though it wouldn’t be my first stop for practical decisions, “<a href="www.jmlr.org/papers/volume3/blei03a/blei03a.pdf">Latent Dirichlet Allocation</a>” (2003).</p></li>
</ul></li>
<li><p><code>eta="auto"</code>: you can think of this setting as, how “chatty” do we want our topics to be? A low eta encourages topics to focus on fewer words, while a high eta encourages more words per topic. I usually select auto as it allows the model to infer how sharp (fewer words) topics should be based on the actual distribution of words in the corpus. In technical literature, you will find this parameter denoted by <span class="math inline">\(\beta\)</span>.</p></li>
<li><p><code>random_state</code>: this will probably seem the most opaque setting. It fixes the sequence of random choices the model makes during initialization. This is a step for reproducibility and transparency. The goal is to be able to obtain the same output from run to run, <strong>but</strong> [flashing warning light, sirens blaring, warning, warning] only in the case that for each run you have the same corpus, the same preprocessing, the all same hyperparamaters settings, the same software versions (!), and the same hardware behavior. We do what we can to be as transparent as possible. Sometimes, life has other plans.</p></li>
</ul>
<p>For more information on all the hyperparameters in <a href="https://radimrehurek.com/gensim/models/ldamodel.html"><strong>gensim’s LDA follow the link</strong></a>. If you really want to dig further into this topic, I strongly recommend <a href="https://proceedings.neurips.cc/paper_files/paper/2009/file/0d0871f0806eae32d30983b62252da50-Paper.pdf"><strong>this paper</strong></a>.</p>
<p>At the end of the day: LDA results depend on modeling choices and random initialization. Different runs can produce different, but equally reasonable, topic structures.</p>
<p>OK, we can finally enjoy the fruits of our labor. Let’s inspect the topics:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> topic_id <span class="kw">in</span> <span class="bu">range</span>(lda.num_topics):</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Topic </span><span class="sc">{</span>topic_id<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, weight <span class="kw">in</span> lda.show_topic(topic_id, topn<span class="op">=</span><span class="dv">12</span>):</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>word<span class="sc">:&gt;12}</span><span class="ss">  </span><span class="sc">{</span>weight<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Topic 0:
        corn  0.020
       wages  0.016
        rent  0.010
      demand  0.008
     profits  0.007
        work  0.007
        rate  0.006
        rise  0.006
 improvement  0.006
        high  0.006
      cattle  0.005
     average  0.005

Topic 1:
        bank  0.043
       paper  0.019
        cent  0.017
        gold  0.015
      silver  0.013
 circulation  0.012
         sum  0.012
       bills  0.010
       notes  0.009
      credit  0.009
      pounds  0.008
       banks  0.008

Topic 2:
     company  0.010
  government  0.009
    colonies  0.008
 established  0.006
   sovereign  0.006
    commerce  0.006
   authority  0.006
      clergy  0.005
         law  0.005
      church  0.005
      empire  0.005
     society  0.005

Topic 3:
      silver  0.043
        gold  0.034
        coin  0.014
      metals  0.012
       mines  0.011
     foreign  0.009
    exchange  0.009
 commodities  0.008
        east  0.008
    purchase  0.007
      annual  0.007
    standard  0.006

Topic 4:
        debt  0.017
         war  0.013
     britain  0.011
         new  0.009
  government  0.009
        fund  0.008
       taxes  0.008
       debts  0.008
    millions  0.007
     chapter  0.007
     private  0.006
       peace  0.006

Topic 5:
         tax  0.034
        rent  0.026
       taxes  0.015
      annual  0.008
  productive  0.007
    landlord  0.007
     society  0.007
      houses  0.006
 consumption  0.006
        fall  0.006
     profits  0.006
       lands  0.006

Topic 6:
     ancient  0.011
   education  0.011
         men  0.009
     society  0.009
        life  0.007
        army  0.006
   authority  0.006
         war  0.006
    standing  0.006
        body  0.006
   exercises  0.006
    military  0.006

Topic 7:
     foreign  0.019
      duties  0.014
     britain  0.013
        home  0.013
 exportation  0.012
 importation  0.010
 consumption  0.009
    colonies  0.009
      bounty  0.009
    monopoly  0.007
        duty  0.007
manufactures  0.007</code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># After training, inspect learned alpha values</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Learned alpha values:"</span>, lda.alpha)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Learned alpha values: [0.08285706 0.04526103 0.07984485 0.06372422 0.04359768 0.05820734
 0.04462427 0.07341722]</code></pre>
</div>
</div>
<p>And let’s visualize them with a bar plot that gives us a representation of the topic prevalence across segments:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> lda.num_topics</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>topic_mass <span class="op">=</span> np.zeros(K)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum topic probabilities over all segments</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bow <span class="kw">in</span> corpus:</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    doc_topics <span class="op">=</span> lda.get_document_topics(bow, minimum_probability<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k, p <span class="kw">in</span> doc_topics:</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>        topic_mass[k] <span class="op">+=</span> p</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize to proportions (so bars sum to 1)</span></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>topic_share <span class="op">=</span> topic_mass <span class="op">/</span> topic_mass.<span class="bu">sum</span>()</span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(K), topic_share)</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(K), [<span class="ss">f"T</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(K)])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>([&lt;matplotlib.axis.XTick object at 0x000001E5D116AC90&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D1646E90&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D16AB390&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D16BD810&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D16AA590&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D16AD2D0&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D16AF690&gt;, &lt;matplotlib.axis.XTick object at 0x000001E5D16C1AD0&gt;], [Text(0, 0, 'T0'), Text(1, 0, 'T1'), Text(2, 0, 'T2'), Text(3, 0, 'T3'), Text(4, 0, 'T4'), Text(5, 0, 'T5'), Text(6, 0, 'T6'), Text(7, 0, 'T7')])</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Share of topic mass (across segments)"</span>)</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Topic"</span>)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"LDA topic prevalence in Wealth of Nations (by segment)"</span>)</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week-07-word2vec_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the numeric values too (useful for interpretation)</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, s <span class="kw">in</span> <span class="bu">enumerate</span>(topic_share):</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Topic </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>s<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Topic 0: 0.204
Topic 1: 0.062
Topic 2: 0.189
Topic 3: 0.119
Topic 4: 0.058
Topic 5: 0.124
Topic 6: 0.071
Topic 7: 0.173</code></pre>
</div>
</div>
<p>Each bar shows the average proportion of that topic across all your 186 segments—i.e., which themes are most prevalent in the book under your segmentation choice.</p>
<p>One more visualization: topic prevalence by segment. This makes the structure of <em>The Wealth of Nations</em> visible.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get per-segment topic distributions</span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>doc_topic_matrix <span class="op">=</span> np.array([</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>    [p <span class="cf">for</span> _, p <span class="kw">in</span> lda.get_document_topics(bow, minimum_probability<span class="op">=</span><span class="dv">0</span>)]</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bow <span class="kw">in</span> corpus</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot only the top 4 topics by overall prevalence (less clutter)</span></span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>top_topics <span class="op">=</span> np.argsort(topic_share)[<span class="op">-</span><span class="dv">4</span>:]</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> top_topics:</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>    plt.plot(doc_topic_matrix[:, k], label<span class="op">=</span><span class="ss">f"Topic </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Segment index (approx. book progression)"</span>)</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Topic proportion"</span>)</span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Topic prevalence across Wealth of Nations"</span>)</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week-07-word2vec_files/figure-html/unnamed-chunk-17-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="final-considerations-and-bringing-things-together" class="level3">
<h3 class="anchored" data-anchor-id="final-considerations-and-bringing-things-together">Final considerations and bringing things together:</h3>
<p>The eight topics our model identified capture distinct but overlapping themes in <em>The Wealth of Nations</em>. Topic 2 (foreign trade and manufactures) and Topic 6 (precious metals and banking) emerge as the most prevalent, together accounting for over a third of the book’s content. This makes sense given Smith’s focus on international commerce and monetary systems. Topic 1 clearly represents taxation and fiscal policy (tax, taxes, duties, Britain), while Topic 3 captures discussions of war, military spending, and colonial companies—particularly the East India Company. Topics 0 and 4 both relate to labor and wages, but Topic 0 emphasizes the relationship between landlords, rent, and maintenance, while Topic 4 focuses more directly on wage rates, employment, and labor markets. Topic 5 centers on agricultural commodities and their prices over time (corn, wheat, cattle, century, improvement), likely reflecting Smith’s extended discussions of agricultural economics and historical price movements. The distribution of topic prevalence tells us something important (and reassuring given what is known about Smith’s work): Smith doesn’t devote equal attention to all themes—international trade and monetary systems clearly dominate his analysis.</p>
<p>As we look at the visualization, we can perhaps get a better sense of some of the structural distribution of these topics. The topic prevalence plot across segments reveals the book’s structure and confirms that LDA has captured meaningful thematic shifts as Smith moves through his argument. Notice how Topic 2 (foreign trade) shows strong presence in the middle and later portions of the book, which aligns with Smith’s extended treatment of commercial policy in Books IV and V. Topic 6 (metals and banking) appears in concentrated bursts rather than being evenly distributed, suggesting Smith returns to monetary questions at specific points in his argument. Topic 3 (war and colonies) is relatively rare overall but spikes sharply in specific segments—these likely correspond to his discussions of colonial administration and military expenditure. The uneven distribution of topics across segments is exactly what we should expect from a structured argument: Smith isn’t randomly mixing concepts and arguments, he’s developing them systematically. If all topics appeared uniformly across all segments, it would suggest either that our segmentation strategy failed to capture the book’s organization, or that LDA wasn’t identifying meaningful thematic distinctions. Instead, the clear peaks and valleys should give us some reassurance that both our preprocessing choices and the model’s topic assignments are capturing real patterns in how Smith structured his economic treatise</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/Astrid-Giugni\.github\.io\/IDS_570_TAD\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>